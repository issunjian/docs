import{_ as a,o as e,c as r,V as o}from"./chunks/framework.c6d8cbec.js";const p=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"interview/backend/kafka/kafka-04.md","filePath":"interview/backend/kafka/kafka-04.md"}'),k={name:"interview/backend/kafka/kafka-04.md"},t=o('<h3 id="_1、监控kafka的框架都有哪些" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#1%E7%9B%91%E6%8E%A7kafka%E7%9A%84%E6%A1%86%E6%9E%B6%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B" target="_blank" rel="noreferrer">1、监控Kafka的框架都有哪些？</a> <a class="header-anchor" href="#_1、监控kafka的框架都有哪些" aria-label="Permalink to &quot;[1、监控Kafka的框架都有哪些？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题，2021年面试题及答案汇总.md#1监控kafka的框架都有哪些)&quot;">​</a></h3><p>对于SRE来讲，依然是送分题。但基础的我们要知道，Kafka本身是提供了JMX（Java Management Extensions）的，我们可以通过它来获取到Kafka内部的一些基本数据。</p><p><strong>1、</strong> Kafka Manager：更多是Kafka的管理，对于SRE非常友好，也提供了简单的瞬时指标监控。</p><p><strong>2、</strong> Kafka Monitor：LinkedIn开源的免费框架，支持对集群进行系统测试，并实时监控测试结果。</p><p><strong>3、</strong> CruiseControl：也是LinkedIn公司开源的监控框架，用于实时监测资源使用率，以及提供常用运维操作等。无UI界面，只提供REST API，可以进行多集群管理。</p><p><strong>4、</strong> JMX监控：由于Kafka提供的监控指标都是基于JMX的，因此，市面上任何能够集成JMX的框架都可以使用，比如Zabbix和Prometheus。</p><p><strong>5、</strong> 已有大数据平台自己的监控体系：像Cloudera提供的CDH这类大数据平台，天然就提供Kafka监控方案。</p><p><strong>6、</strong> JMXTool：社区提供的命令行工具，能够实时监控JMX指标。可以使用Kafka-run-class.sh Kafka.tools.JmxTool来查看具体的用法。</p><h3 id="_2、kafka的主要api有哪些" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#2kafka%E7%9A%84%E4%B8%BB%E8%A6%81api%E6%9C%89%E5%93%AA%E4%BA%9B" target="_blank" rel="noreferrer">2、Kafka的主要API有哪些？</a> <a class="header-anchor" href="#_2、kafka的主要api有哪些" aria-label="Permalink to &quot;[2、Kafka的主要API有哪些？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题，2021年面试题及答案汇总.md#2kafka的主要api有哪些)&quot;">​</a></h3><p>Apache Kafka有4个主要API：</p><p>生产者API 消费者API 流 API 连接器API</p><h3 id="_3、解释领导者和追随者的概念。" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#3%E8%A7%A3%E9%87%8A%E9%A2%86%E5%AF%BC%E8%80%85%E5%92%8C%E8%BF%BD%E9%9A%8F%E8%80%85%E7%9A%84%E6%A6%82%E5%BF%B5%E3%80%82" target="_blank" rel="noreferrer">3、解释领导者和追随者的概念。</a> <a class="header-anchor" href="#_3、解释领导者和追随者的概念。" aria-label="Permalink to &quot;[3、解释领导者和追随者的概念。](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题，2021年面试题及答案汇总.md#3解释领导者和追随者的概念。)&quot;">​</a></h3><p>在Kafka的每个分区中，都有一个服务器充当领导者，0到多个服务器充当追随者的角色。</p><h3 id="_4、kafka-如何实现延迟队列" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#4kafka-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97" target="_blank" rel="noreferrer">4、Kafka 如何实现延迟队列?</a> <a class="header-anchor" href="#_4、kafka-如何实现延迟队列" aria-label="Permalink to &quot;[4、Kafka 如何实现延迟队列?](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题，2021年面试题及答案汇总.md#4kafka-如何实现延迟队列)&quot;">​</a></h3><p>Kafka并没有使用JDK自带的Timer或者DelayQueue来实现延迟的功能，而是<strong>基于时间轮自定义了一个用于实现延迟功能的定时器（SystemTimer）</strong>。JDK的Timer和DelayQueue插入和删除操作的平均时间复杂度为O(nlog(n))，并不能满足Kafka的高性能要求，而基于时间轮可以将插入和删除操作的时间复杂度都降为<strong>O(1)</strong>。时间轮的应用并非Kafka独有，其应用场景还有很多，在Netty、Akka、Quartz、Zookeeper等组件中都存在时间轮的踪影。</p><p>底层使用数组实现，数组中的每个元素可以存放一个TimerTaskList对象。TimerTaskList是一个环形双向链表，在其中的链表项TimerTaskEntry中封装了真正的定时任务TimerTask.</p><p>Kafka中到底是怎么推进时间的呢？Kafka中的定时器借助了JDK中的DelayQueue来协助推进时间轮。具体做法是对于每个使用到的TimerTaskList都会加入到DelayQueue中。<strong>Kafka中的TimingWheel专门用来执行插入和删除TimerTaskEntry的操作，而DelayQueue专门负责时间推进的任务</strong>。再试想一下，DelayQueue中的第一个超时任务列表的expiration为200ms，第二个超时任务为840ms，这里获取DelayQueue的队头只需要O(1)的时间复杂度。如果采用每秒定时推进，那么获取到第一个超时的任务列表时执行的200次推进中有199次属于“空推进”，而获取到第二个超时任务时有需要执行639次“空推进”，这样会无故空耗机器的性能资源，这里采用DelayQueue来辅助以少量空间换时间，从而做到了“精准推进”。Kafka中的定时器真可谓是“知人善用”，用TimingWheel做最擅长的任务添加和删除操作，而用DelayQueue做最擅长的时间推进工作，相辅相成。</p><h3 id="_5、为什么kafka不支持读写分离" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#5%E4%B8%BA%E4%BB%80%E4%B9%88kafka%E4%B8%8D%E6%94%AF%E6%8C%81%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB" target="_blank" rel="noreferrer">5、为什么Kafka不支持读写分离？</a> <a class="header-anchor" href="#_5、为什么kafka不支持读写分离" aria-label="Permalink to &quot;[5、为什么Kafka不支持读写分离？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题，2021年面试题及答案汇总.md#5为什么kafka不支持读写分离)&quot;">​</a></h3><p>在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种<strong>主写主读</strong>的生产消费模型。</p><p>Kafka 并不支持主写从读，因为主写从读有 2 个很明 显的缺点:</p><p><strong>数据一致性问题</strong>。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。</p><p><strong>延时问题</strong>。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经 历网络→主节点内存→网络→从节点内存这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘→网络→从节 点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。</p><h3 id="_6、kafka-消息是采用-pull-模式-还是-push-模式" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#6kafka-%E6%B6%88%E6%81%AF%E6%98%AF%E9%87%87%E7%94%A8-pull-%E6%A8%A1%E5%BC%8F%E8%BF%98%E6%98%AF-push-%E6%A8%A1%E5%BC%8F" target="_blank" rel="noreferrer">6、Kafka 消息是采用 Pull 模式，还是 Push 模式？</a> <a class="header-anchor" href="#_6、kafka-消息是采用-pull-模式-还是-push-模式" aria-label="Permalink to &quot;[6、Kafka 消息是采用 Pull 模式，还是 Push 模式？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题，2021年面试题及答案汇总.md#6kafka-消息是采用-pull-模式还是-push-模式)&quot;">​</a></h3><p>Kafka 最初考虑的问题是，customer 应该从 brokes 拉取消息还是 brokers 将消息推送到</p><p>consumer，也就是 pull 还 push。在这方面，Kafka 遵循了一种大部分消息系统共同的传统</p><p>的设计：</p><p>producer 将消息推送到 broker，consumer 从 broker 拉取消息</p><p>一些消息系统比如 Scribe 和 Apache Flume 采用了 push 模式，将消息推送到下游的</p><p>consumer。</p><p>这样做有好处也有坏处：由 broker 决定消息推送的速率，对于不同消费速率的</p><p>consumer 就不太好处理了。消息系统都致力于让 consumer 以最大的速率最快速的消费消</p><p>息，但不幸的是，push 模式下，当 broker 推送的速率远大于 consumer 消费的速率时，</p><p>consumer 恐怕就要崩溃了。最终 Kafka 还是选取了传统的 pull 模式</p><p>Pull 模式的另外一个好处是 consumer 可以自主决定是否批量的从 broker 拉取数据。Push</p><p>模式必须在不知道下游 consumer 消费能力和消费策略的情况下决定是立即推送每条消息还</p><p>是缓存之后批量推送。如果为了避免 consumer 崩溃而采用较低的推送速率，将可能导致一</p><p>次只推送较少的消息而造成浪费。Pull 模式下，consumer 就可以根据自己的消费能力去决</p><p>定这些策略</p><p>Pull 有个缺点是，如果 broker 没有可供消费的消息，将导致 consumer 不断在循环中轮询，</p><p>直到新消息到 t 达。为了避免这点，Kafka 有个参数可以让 consumer 阻塞知道新消息到达</p><p>(当然也可以阻塞知道消息的数量达到某个特定的量这样就可以批量发</p><h3 id="_7、为什么要使用apache-kafka集群" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#7%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8apache-kafka%E9%9B%86%E7%BE%A4" target="_blank" rel="noreferrer">7、为什么要使用Apache Kafka集群？</a> <a class="header-anchor" href="#_7、为什么要使用apache-kafka集群" aria-label="Permalink to &quot;[7、为什么要使用Apache Kafka集群？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题，2021年面试题及答案汇总.md#7为什么要使用apache-kafka集群)&quot;">​</a></h3><p>为了克服收集大量数据和分析收集数据的挑战，我们需要一个消息队列系统。因此Apache Kafka应运而生。其好处是：只需存储/发送事件以进行实时处理，就可以跟踪Web活动。通过这一点，我们可以发出警报并报告操作指标。此外，我们可以将数据转换为标准格式。此外，它允许对主题的流数据进行连续处理。由于它的广泛使用，它秒杀了竞品，如ActiveMQ，RabbitMQ等。</p><h3 id="_8、kafka中的-isr、ar-又代表什么-isr-的伸缩又指什么" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#8kafka%E4%B8%AD%E7%9A%84-israr-%E5%8F%88%E4%BB%A3%E8%A1%A8%E4%BB%80%E4%B9%88isr-%E7%9A%84%E4%BC%B8%E7%BC%A9%E5%8F%88%E6%8C%87%E4%BB%80%E4%B9%88" target="_blank" rel="noreferrer">8、Kafka中的 ISR、AR 又代表什么？ISR 的伸缩又指什么？</a> <a class="header-anchor" href="#_8、kafka中的-isr、ar-又代表什么-isr-的伸缩又指什么" aria-label="Permalink to &quot;[8、Kafka中的 ISR、AR 又代表什么？ISR 的伸缩又指什么？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题，2021年面试题及答案汇总.md#8kafka中的-israr-又代表什么isr-的伸缩又指什么)&quot;">​</a></h3><p><strong>ISR</strong>：In-Sync Replicas 副本同步队列；ISR是由leader维护，follower从leader同步数据有一些延迟（包括延迟时间replica.lag.time.max.ms和延迟条数replica.lag.max.messages两个维度, 版本0.10.x中只支持replica.lag.time.max.ms这个维度），任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR。</p><p><strong>AR</strong>：Assigned Replicas 所有副本；</p><h3 id="_9、kafka-producer-写数据-ack-为-0-1-1-时分别代表什么" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#9kafka-producer-%E5%86%99%E6%95%B0%E6%8D%AEack-%E4%B8%BA-01-1-%E6%97%B6%E5%88%86%E5%88%AB%E4%BB%A3%E8%A1%A8%E4%BB%80%E4%B9%88" target="_blank" rel="noreferrer">9、Kafka Producer 写数据，ACK 为 0，1，-1 时分别代表什么？</a> <a class="header-anchor" href="#_9、kafka-producer-写数据-ack-为-0-1-1-时分别代表什么" aria-label="Permalink to &quot;[9、Kafka Producer 写数据，ACK 为 0，1，-1 时分别代表什么？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题，2021年面试题及答案汇总.md#9kafka-producer-写数据ack-为-01-1-时分别代表什么)&quot;">​</a></h3><p>1（默认） 数据发送到Kafka后，经过leader成功接收消息的的确认，就算是发送成功了。在这种情况下，如果leader宕机了，则会丢失数据。</p><p>0 生产者将数据发送出去就不管了，不去等待任何返回。这种情况下数据传输效率最高，但是数据可靠性确是最低的。</p><p>-1 producer需要等待ISR中的所有follower都确认接收到数据后才算一次发送完成，可靠性最高。</p><h3 id="_10、leader总是-1-怎么破" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#10leader%E6%80%BB%E6%98%AF-1%E6%80%8E%E4%B9%88%E7%A0%B4" target="_blank" rel="noreferrer">10、Leader总是-1，怎么破？</a> <a class="header-anchor" href="#_10、leader总是-1-怎么破" aria-label="Permalink to &quot;[10、Leader总是-1，怎么破？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题，2021年面试题及答案汇总.md#10leader总是-1怎么破)&quot;">​</a></h3><p><strong>1、</strong> 对于有经验的SRE来讲，早期的Kafka版本应该多多少少都遇到过该种情况，通常情况下就是Controller不工作了，导致无法分配leader，那既然知道问题后，解决方案也就很简单了。重启Controller节点上的Kafka进程，让其他节点重新注册Controller角色，但是如上面ZooKeeper的作用，你要知道为什么Controller可以自动注册。</p><p><strong>2、</strong> 当然了，当你知道controller的注册机制后，你也可以说：删除ZooKeeper节点/controller，触发Controller重选举。Controller重选举能够为所有主题分区重刷分区状态，可以有效解决因不一致导致的 Leader 不可用问题。但是，需要注意的是，直接操作ZooKeeper是一件风险很大的操作，就好比在Linux中执行了rm -rf /xxx一样，如果在/和xxx之间不小心多了几个空格，那”恭喜你”，今年白干了。</p><h3 id="_11、kafaka-生产数据时数据的分组策略" tabindex="-1">11、kafaka 生产数据时数据的分组策略 <a class="header-anchor" href="#_11、kafaka-生产数据时数据的分组策略" aria-label="Permalink to &quot;11、kafaka 生产数据时数据的分组策略&quot;">​</a></h3><h3 id="_12、kafka和flume之间的主要区别是什么" tabindex="-1">12、Kafka和Flume之间的主要区别是什么？ <a class="header-anchor" href="#_12、kafka和flume之间的主要区别是什么" aria-label="Permalink to &quot;12、Kafka和Flume之间的主要区别是什么？&quot;">​</a></h3><h3 id="_13、kafka-的设计时什么样的呢" tabindex="-1">13、Kafka 的设计时什么样的呢？ <a class="header-anchor" href="#_13、kafka-的设计时什么样的呢" aria-label="Permalink to &quot;13、Kafka 的设计时什么样的呢？&quot;">​</a></h3><h3 id="_14、zookeeper在kafka中的作用是什么" tabindex="-1">14、ZooKeeper在Kafka中的作用是什么？ <a class="header-anchor" href="#_14、zookeeper在kafka中的作用是什么" aria-label="Permalink to &quot;14、ZooKeeper在Kafka中的作用是什么？&quot;">​</a></h3><h3 id="_15、为什么kafka技术很重要" tabindex="-1">15、为什么Kafka技术很重要？ <a class="header-anchor" href="#_15、为什么kafka技术很重要" aria-label="Permalink to &quot;15、为什么Kafka技术很重要？&quot;">​</a></h3><h3 id="_16、-21-23-25-26-27-28-29-30apache-kafka对于有经验的人的面试" tabindex="-1">16、：21, 23, 25, 26, 27, 28, 29, 30Apache Kafka对于有经验的人的面试 <a class="header-anchor" href="#_16、-21-23-25-26-27-28-29-30apache-kafka对于有经验的人的面试" aria-label="Permalink to &quot;16、：21, 23, 25, 26, 27, 28, 29, 30Apache Kafka对于有经验的人的面试&quot;">​</a></h3><h3 id="_17、kafka-producer-api的作用是什么" tabindex="-1">17、Kafka Producer API的作用是什么？ <a class="header-anchor" href="#_17、kafka-producer-api的作用是什么" aria-label="Permalink to &quot;17、Kafka Producer API的作用是什么？&quot;">​</a></h3><h3 id="_18、kafa-consumer-是否可以消费指定分区消息" tabindex="-1">18、Kafa consumer 是否可以消费指定分区消息？ <a class="header-anchor" href="#_18、kafa-consumer-是否可以消费指定分区消息" aria-label="Permalink to &quot;18、Kafa consumer 是否可以消费指定分区消息？&quot;">​</a></h3><h3 id="_19、如果-leader-crash-时-isr为空怎么办" tabindex="-1">19、如果 Leader Crash 时，ISR为空怎么办 <a class="header-anchor" href="#_19、如果-leader-crash-时-isr为空怎么办" aria-label="Permalink to &quot;19、如果 Leader Crash 时，ISR为空怎么办&quot;">​</a></h3><h3 id="_20、什么是消费者或用户" tabindex="-1">20、什么是消费者或用户？ <a class="header-anchor" href="#_20、什么是消费者或用户" aria-label="Permalink to &quot;20、什么是消费者或用户？&quot;">​</a></h3><h3 id="_21、解释如何调整kafka以获得最佳性能。" tabindex="-1">21、解释如何调整Kafka以获得最佳性能。 <a class="header-anchor" href="#_21、解释如何调整kafka以获得最佳性能。" aria-label="Permalink to &quot;21、解释如何调整Kafka以获得最佳性能。&quot;">​</a></h3><h3 id="_22、你能用kafka做什么" tabindex="-1">22、你能用Kafka做什么？ <a class="header-anchor" href="#_22、你能用kafka做什么" aria-label="Permalink to &quot;22、你能用Kafka做什么？&quot;">​</a></h3><h3 id="_23、kafka的优点有那些" tabindex="-1">23、Kafka的优点有那些？ <a class="header-anchor" href="#_23、kafka的优点有那些" aria-label="Permalink to &quot;23、Kafka的优点有那些？&quot;">​</a></h3><h3 id="_24、kafka的一些最显著的应用。" tabindex="-1">24、Kafka的一些最显著的应用。 <a class="header-anchor" href="#_24、kafka的一些最显著的应用。" aria-label="Permalink to &quot;24、Kafka的一些最显著的应用。&quot;">​</a></h3><h3 id="_25、生产者和消费者的命令行是什么" tabindex="-1">25、生产者和消费者的命令行是什么？ <a class="header-anchor" href="#_25、生产者和消费者的命令行是什么" aria-label="Permalink to &quot;25、生产者和消费者的命令行是什么？&quot;">​</a></h3><h3 id="_26、如何获取topic主题的列表" tabindex="-1">26、如何获取topic主题的列表 <a class="header-anchor" href="#_26、如何获取topic主题的列表" aria-label="Permalink to &quot;26、如何获取topic主题的列表&quot;">​</a></h3><h3 id="_27、kafka什么情况下会rebalance" tabindex="-1">27、Kafka什么情况下会rebalance <a class="header-anchor" href="#_27、kafka什么情况下会rebalance" aria-label="Permalink to &quot;27、Kafka什么情况下会rebalance&quot;">​</a></h3><h3 id="_28、什么是消费者组" tabindex="-1">28、什么是消费者组？ <a class="header-anchor" href="#_28、什么是消费者组" aria-label="Permalink to &quot;28、什么是消费者组？&quot;">​</a></h3>',71),s=[t];function E(l,f,n,i,h,u){return e(),r("div",null,s)}const d=a(k,[["render",E]]);export{p as __pageData,d as default};
