import{_ as a,o as e,c as o,V as r}from"./chunks/framework.c6d8cbec.js";const A=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"interview/backend/kafka/kafka-05.md","filePath":"interview/backend/kafka/kafka-05.md"}'),k={name:"interview/backend/kafka/kafka-05.md"},t=r('<h3 id="_1、3-它还可以在记录进入时对其进行处理。apache-kafka对于新手的面试" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#13%E5%AE%83%E8%BF%98%E5%8F%AF%E4%BB%A5%E5%9C%A8%E8%AE%B0%E5%BD%95%E8%BF%9B%E5%85%A5%E6%97%B6%E5%AF%B9%E5%85%B6%E8%BF%9B%E8%A1%8C%E5%A4%84%E7%90%86%E3%80%82apache-kafka%E5%AF%B9%E4%BA%8E%E6%96%B0%E6%89%8B%E7%9A%84%E9%9D%A2%E8%AF%95" target="_blank" rel="noreferrer">1、3.它还可以在记录进入时对其进行处理。Apache Kafka对于新手的面试</a> <a class="header-anchor" href="#_1、3-它还可以在记录进入时对其进行处理。apache-kafka对于新手的面试" aria-label="Permalink to &quot;[1、3.它还可以在记录进入时对其进行处理。Apache Kafka对于新手的面试](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题2021年，常见面试题及答案汇总.md#13它还可以在记录进入时对其进行处理。apache-kafka对于新手的面试)&quot;">​</a></h3><h3 id="_2、broker的heap-size如何设置" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#2broker%E7%9A%84heap-size%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AE" target="_blank" rel="noreferrer">2、Broker的Heap Size如何设置？</a> <a class="header-anchor" href="#_2、broker的heap-size如何设置" aria-label="Permalink to &quot;[2、Broker的Heap Size如何设置？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题2021年，常见面试题及答案汇总.md#2broker的heap-size如何设置)&quot;">​</a></h3><p><strong>1、</strong> 其实对于SRE还是送分题，因为目前来讲大部分公司的业务系统都是使用Java开发，因此SRE对于基本的JVM相关的参数应该至少都是非常了解的，核心就在于JVM的配置以及GC相关的知识。</p><p><strong>2、</strong> 标准答案：任何Java进程JVM堆大小的设置都需要仔细地进行考量和测试。一个常见的做法是，以默认的初始JVM堆大小运行程序，当系统达到稳定状态后，手动触发一次Full GC，然后通过JVM工具查看GC后的存活对象大小。之后，将堆大小设置成存活对象总大小的1.5~2倍。对于Kafka而言，这个方法也是适用的。不过，业界有个最佳实践，那就是将Broker的Heap Size固定为6GB。经过很多公司的验证，这个大小是足够且良好的。</p><h3 id="_3、rebalance有什么影响" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#3rebalance%E6%9C%89%E4%BB%80%E4%B9%88%E5%BD%B1%E5%93%8D" target="_blank" rel="noreferrer">3、Rebalance有什么影响</a> <a class="header-anchor" href="#_3、rebalance有什么影响" aria-label="Permalink to &quot;[3、Rebalance有什么影响](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题2021年，常见面试题及答案汇总.md#3rebalance有什么影响)&quot;">​</a></h3><p>Rebalance本身是Kafka集群的一个保护设定，用于剔除掉无法消费或者过慢的消费者，然后由于我们的数据量较大，同时后续消费后的数据写入需要走网络IO，很有可能存在依赖的第三方服务存在慢的情况而导致我们超时。Rebalance对我们数据的影响主要有以下几点：</p><p>数据重复消费: 消费过的数据由于提交offset任务也会失败，在partition被分配给其他消费者的时候，会造成重复消费，数据重复且增加集群压力</p><p>Rebalance扩散到整个ConsumerGroup的所有消费者，因为一个消费者的退出，导致整个Group进行了Rebalance，并在一个比较慢的时间内达到稳定状态，影响面较大</p><p>频繁的Rebalance反而降低了消息的消费速度，大部分时间都在重复消费和Rebalance</p><p>数据不能及时消费，会累积lag，在Kafka的TTL之后会丢弃数据 上面的影响对于我们系统来说，都是致命的。</p><h3 id="_4、kafka的高可用机制是什么" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#4kafka%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9C%BA%E5%88%B6%E6%98%AF%E4%BB%80%E4%B9%88" target="_blank" rel="noreferrer">4、Kafka的高可用机制是什么？</a> <a class="header-anchor" href="#_4、kafka的高可用机制是什么" aria-label="Permalink to &quot;[4、Kafka的高可用机制是什么？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题2021年，常见面试题及答案汇总.md#4kafka的高可用机制是什么)&quot;">​</a></h3><p>这个问题比较系统，回答出Kafka的系统特点，leader和follower的关系，消息读写的顺序即可。</p><p><a href="https://www.cnblogs.com/qingyunzong/p/9004703.html" target="_blank" rel="noreferrer">https://www.cnblogs.com/qingyunzong/p/9004703.html</a></p><p><a href="https://www.tuicool.com/articles/BNRza2E" target="_blank" rel="noreferrer">https://www.tuicool.com/articles/BNRza2E</a></p><p><a href="https://yq.aliyun.com/articles/64703" target="_blank" rel="noreferrer">https://yq.aliyun.com/articles/64703</a></p><h3 id="_5、解释kafka可以接收的消息最大为多少" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#5%E8%A7%A3%E9%87%8Akafka%E5%8F%AF%E4%BB%A5%E6%8E%A5%E6%94%B6%E7%9A%84%E6%B6%88%E6%81%AF%E6%9C%80%E5%A4%A7%E4%B8%BA%E5%A4%9A%E5%B0%91" target="_blank" rel="noreferrer">5、解释Kafka可以接收的消息最大为多少？</a> <a class="header-anchor" href="#_5、解释kafka可以接收的消息最大为多少" aria-label="Permalink to &quot;[5、解释Kafka可以接收的消息最大为多少？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题2021年，常见面试题及答案汇总.md#5解释kafka可以接收的消息最大为多少)&quot;">​</a></h3><p>Kafka可以接收的最大消息大小约为1000000字节。</p><h3 id="_6、kafka流的特点。" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#6kafka%E6%B5%81%E7%9A%84%E7%89%B9%E7%82%B9%E3%80%82" target="_blank" rel="noreferrer">6、Kafka流的特点。</a> <a class="header-anchor" href="#_6、kafka流的特点。" aria-label="Permalink to &quot;[6、Kafka流的特点。](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题2021年，常见面试题及答案汇总.md#6kafka流的特点。)&quot;">​</a></h3><p>Kafka流的一些最佳功能是Kafka Streams具有高度可扩展性和容错性。Kafka部署到容器，VM，裸机，云。我们可以说，Kafka流对于小型，中型和大型用例同样可行。此外，它完全与Kafka安全集成。编写标准Java应用程序。完全一次处理语义。而且，不需要单独的处理集群。</p><h3 id="_7、kafka-follower如何与leader同步数据" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#7kafka-follower%E5%A6%82%E4%BD%95%E4%B8%8Eleader%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE" target="_blank" rel="noreferrer">7、Kafka Follower如何与Leader同步数据?</a> <a class="header-anchor" href="#_7、kafka-follower如何与leader同步数据" aria-label="Permalink to &quot;[7、Kafka Follower如何与Leader同步数据?](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题2021年，常见面试题及答案汇总.md#7kafka-follower如何与leader同步数据)&quot;">​</a></h3><p>Kafka 的复制机制既不是完全的同步复制，也不是单纯的异步复制。完全同步复制要求 All Alive Follower 都复制完，这条消息才会被认为 commit，这种复制方式极大的影响了吞吐率。而异步复制方式下，Follower 异步的从 Leader 复制数据，数据只要被 Leader 写入 log 就被认为已经 commit，这种情况下，如果 leader 挂掉，会丢失数据，Kafka 使用 ISR 的方式很好的均衡了确保数据不丢失以及吞吐率。Follower 可以批量的从 Leader 复制数据，而且 Leader 充分利用磁盘顺序读以及 send file(zero copy) 机制，这样极大的提高复制性能，内部批量写磁盘，大幅减少了 Follower 与 Leader 的消息量差。</p><h3 id="_8、kafka的哪些场景中使用了零拷贝-zero-copy" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#8kafka%E7%9A%84%E5%93%AA%E4%BA%9B%E5%9C%BA%E6%99%AF%E4%B8%AD%E4%BD%BF%E7%94%A8%E4%BA%86%E9%9B%B6%E6%8B%B7%E8%B4%9Dzero-copy" target="_blank" rel="noreferrer">8、Kafka的哪些场景中使用了零拷贝（Zero Copy）？</a> <a class="header-anchor" href="#_8、kafka的哪些场景中使用了零拷贝-zero-copy" aria-label="Permalink to &quot;[8、Kafka的哪些场景中使用了零拷贝（Zero Copy）？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题2021年，常见面试题及答案汇总.md#8kafka的哪些场景中使用了零拷贝zero-copy)&quot;">​</a></h3><p><strong>1、</strong> 其实这道题对于SRE来讲，有点超纲了，不过既然Zero Copy是Kafka高性能的保证，我们需要了解它。</p><p><strong>2、</strong> Zero Copy是特别容易被问到的高阶题目。在Kafka中，体现Zero Copy使用场景的地方有两处：基于mmap的索引和日志文件读写所用的TransportLayer。</p><p><strong>3、</strong> 先说第一个。索引都是基于MappedByteBuffer的，也就是让用户态和内核态共享内核态的数据缓冲区，此时，数据不需要复制到用户态空间。不过，mmap虽然避免了不必要的拷贝，但不一定就能保证很高的性能。在不同的操作系统下，mmap的创建和销毁成本可能是不一样的。很高的创建和销毁开销会抵消Zero Copy带来的性能优势。由于这种不确定性，在Kafka中，只有索引应用了mmap，最核心的日志并未使用mmap机制。</p><p><strong>4、</strong> 再说第二个。TransportLayer是Kafka传输层的接口。它的某个实现类使用了FileChannel的transferTo方法。该方法底层使用sendfile实现了Zero Copy。对Kafka而言，如果I/O通道使用普通的PLAINTEXT，那么，Kafka就可以利用Zero Copy特性，直接将页缓存中的数据发送到网卡的Buffer中，避免中间的多次拷贝。相反，如果I/O通道启用了SSL，那么，Kafka便无法利用Zero Copy特性了。</p><h3 id="_9、副本长时间不在isr中-这意味着什么" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#9%E5%89%AF%E6%9C%AC%E9%95%BF%E6%97%B6%E9%97%B4%E4%B8%8D%E5%9C%A8isr%E4%B8%AD%E8%BF%99%E6%84%8F%E5%91%B3%E7%9D%80%E4%BB%80%E4%B9%88" target="_blank" rel="noreferrer">9、副本长时间不在ISR中，这意味着什么？</a> <a class="header-anchor" href="#_9、副本长时间不在isr中-这意味着什么" aria-label="Permalink to &quot;[9、副本长时间不在ISR中，这意味着什么？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题2021年，常见面试题及答案汇总.md#9副本长时间不在isr中这意味着什么)&quot;">​</a></h3><p>意味着 follower 不能像 leader 收集数据那样快速地获取数据。</p><h3 id="_10、-46-48" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#10%EF%BC%9A46,-48" target="_blank" rel="noreferrer">10、：46, 48</a> <a class="header-anchor" href="#_10、-46-48" aria-label="Permalink to &quot;[10、：46, 48](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题2021年，常见面试题及答案汇总.md#10：46,-48)&quot;">​</a></h3><h3 id="_11、kafka中的数据日志是什么" tabindex="-1">11、Kafka中的数据日志是什么？ <a class="header-anchor" href="#_11、kafka中的数据日志是什么" aria-label="Permalink to &quot;11、Kafka中的数据日志是什么？&quot;">​</a></h3><h3 id="_12、kafka为何这么快" tabindex="-1">12、Kafka为何这么快 <a class="header-anchor" href="#_12、kafka为何这么快" aria-label="Permalink to &quot;12、Kafka为何这么快&quot;">​</a></h3><h3 id="_13、kafka-创建-topic-时如何将分区放置到不同的-broker-中" tabindex="-1">13、Kafka 创建 Topic 时如何将分区放置到不同的 Broker 中 <a class="header-anchor" href="#_13、kafka-创建-topic-时如何将分区放置到不同的-broker-中" aria-label="Permalink to &quot;13、Kafka 创建 Topic 时如何将分区放置到不同的 Broker 中&quot;">​</a></h3><h3 id="_14、消费者故障-出现活锁问题如何解决" tabindex="-1">14、消费者故障，出现活锁问题如何解决？ <a class="header-anchor" href="#_14、消费者故障-出现活锁问题如何解决" aria-label="Permalink to &quot;14、消费者故障，出现活锁问题如何解决？&quot;">​</a></h3><h3 id="_15、什么是apache-kafka" tabindex="-1">15、什么是Apache Kafka? <a class="header-anchor" href="#_15、什么是apache-kafka" aria-label="Permalink to &quot;15、什么是Apache Kafka?&quot;">​</a></h3><h3 id="_16、传统的消息传递方法有哪些类型" tabindex="-1">16、传统的消息传递方法有哪些类型？ <a class="header-anchor" href="#_16、传统的消息传递方法有哪些类型" aria-label="Permalink to &quot;16、传统的消息传递方法有哪些类型？&quot;">​</a></h3><h3 id="_17、consumer-offsets是做什么用的" tabindex="-1">17、consumer_offsets是做什么用的？ <a class="header-anchor" href="#_17、consumer-offsets是做什么用的" aria-label="Permalink to &quot;17、consumer_offsets是做什么用的？&quot;">​</a></h3><h3 id="_18、解释kafka-producer-api的作用。" tabindex="-1">18、解释Kafka Producer API的作用。 <a class="header-anchor" href="#_18、解释kafka-producer-api的作用。" aria-label="Permalink to &quot;18、解释Kafka Producer API的作用。&quot;">​</a></h3><h3 id="_19、阐述下-kafka-中的领导者副本-leader-replica-和追随者副本-follower-replica-的区别" tabindex="-1">19、阐述下 Kafka 中的领导者副本（Leader Replica）和追随者副本（Follower Replica）的区别 <a class="header-anchor" href="#_19、阐述下-kafka-中的领导者副本-leader-replica-和追随者副本-follower-replica-的区别" aria-label="Permalink to &quot;19、阐述下 Kafka 中的领导者副本（Leader Replica）和追随者副本（Follower Replica）的区别&quot;">​</a></h3><h3 id="_20、讲讲kafka维护消费状态跟踪的方法" tabindex="-1">20、讲讲Kafka维护消费状态跟踪的方法 <a class="header-anchor" href="#_20、讲讲kafka维护消费状态跟踪的方法" aria-label="Permalink to &quot;20、讲讲Kafka维护消费状态跟踪的方法&quot;">​</a></h3><h3 id="_21、kafka-的消费者如何消费数据" tabindex="-1">21、Kafka 的消费者如何消费数据 <a class="header-anchor" href="#_21、kafka-的消费者如何消费数据" aria-label="Permalink to &quot;21、Kafka 的消费者如何消费数据&quot;">​</a></h3><h3 id="_22、为什么kafka的复制至关重要" tabindex="-1">22、为什么Kafka的复制至关重要？ <a class="header-anchor" href="#_22、为什么kafka的复制至关重要" aria-label="Permalink to &quot;22、为什么Kafka的复制至关重要？&quot;">​</a></h3><h3 id="_23、如何保证kafka顺序消费" tabindex="-1">23、如何保证Kafka顺序消费 <a class="header-anchor" href="#_23、如何保证kafka顺序消费" aria-label="Permalink to &quot;23、如何保证Kafka顺序消费&quot;">​</a></h3><h3 id="_24、apache-kafka是分布式流处理平台吗-如果是-你能用它做什么" tabindex="-1">24、Apache Kafka是分布式流处理平台吗？如果是，你能用它做什么？ <a class="header-anchor" href="#_24、apache-kafka是分布式流处理平台吗-如果是-你能用它做什么" aria-label="Permalink to &quot;24、Apache Kafka是分布式流处理平台吗？如果是，你能用它做什么？&quot;">​</a></h3><h3 id="_25、为什么kafka的复制至关重要" tabindex="-1">25、为什么Kafka的复制至关重要？ <a class="header-anchor" href="#_25、为什么kafka的复制至关重要" aria-label="Permalink to &quot;25、为什么Kafka的复制至关重要？&quot;">​</a></h3><h3 id="_26、消费者如何不自动提交偏移量-由应用提交" tabindex="-1">26、消费者如何不自动提交偏移量，由应用提交？ <a class="header-anchor" href="#_26、消费者如何不自动提交偏移量-由应用提交" aria-label="Permalink to &quot;26、消费者如何不自动提交偏移量，由应用提交？&quot;">​</a></h3><h3 id="_27、kafka-新建的分区会在哪个目录下创建" tabindex="-1">27、Kafka 新建的分区会在哪个目录下创建 <a class="header-anchor" href="#_27、kafka-新建的分区会在哪个目录下创建" aria-label="Permalink to &quot;27、Kafka 新建的分区会在哪个目录下创建&quot;">​</a></h3><h3 id="_28、kafka中的-zookeeper-起到什么作用-可以不用zookeeper吗" tabindex="-1">28、Kafka中的 zookeeper 起到什么作用？可以不用zookeeper吗？ <a class="header-anchor" href="#_28、kafka中的-zookeeper-起到什么作用-可以不用zookeeper吗" aria-label="Permalink to &quot;28、Kafka中的 zookeeper 起到什么作用？可以不用zookeeper吗？&quot;">​</a></h3>',47),E=[t];function l(f,s,h,n,i,B){return e(),o("div",null,E)}const d=a(k,[["render",l]]);export{A as __pageData,d as default};
