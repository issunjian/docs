import{_ as a,o as e,c as o,V as r}from"./chunks/framework.c6d8cbec.js";const c=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"interview/backend/大数据/大数据-05.md","filePath":"interview/backend/大数据/大数据-05.md"}'),t={name:"interview/backend/大数据/大数据-05.md"},E=r('<h3 id="_1、什么是dag" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#1%E4%BB%80%E4%B9%88%E6%98%AFdag" target="_blank" rel="noreferrer">1、什么是DAG</a> <a class="header-anchor" href="#_1、什么是dag" aria-label="Permalink to &quot;[1、什么是DAG](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题，2021年面试题及答案汇总.md#1什么是dag)&quot;">​</a></h3><p>叫有向无环图，原始RDD通过转换形成DAG，RDD之间的依赖关系的不同划分为不同的Stage调度阶段</p><h3 id="_2、为什么会产生rdd" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#2%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E4%BA%A7%E7%94%9Frdd" target="_blank" rel="noreferrer">2、为什么会产生RDD</a> <a class="header-anchor" href="#_2、为什么会产生rdd" aria-label="Permalink to &quot;[2、为什么会产生RDD](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题，2021年面试题及答案汇总.md#2为什么会产生rdd)&quot;">​</a></h3><p>什么是窄依赖，宽依赖</p><p>窄依赖指的是每一个父RDD的partition最多被子RDD的一个Partition使用</p><p>一对一</p><p>宽依赖指的是多个子RDD的partition会依赖于同一个父RDD的partition</p><p>多对一</p><h3 id="_3、如果在ssh中添加key-是否还需要设置密码" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#3%E5%A6%82%E6%9E%9C%E5%9C%A8ssh%E4%B8%AD%E6%B7%BB%E5%8A%A0key%E6%98%AF%E5%90%A6%E8%BF%98%E9%9C%80%E8%A6%81%E8%AE%BE%E7%BD%AE%E5%AF%86%E7%A0%81" target="_blank" rel="noreferrer">3、如果在SSH中添加key，是否还需要设置密码？</a> <a class="header-anchor" href="#_3、如果在ssh中添加key-是否还需要设置密码" aria-label="Permalink to &quot;[3、如果在SSH中添加key，是否还需要设置密码？](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题，2021年面试题及答案汇总.md#3如果在ssh中添加key是否还需要设置密码)&quot;">​</a></h3><p>是的，即使在SSH中添加了key，还是需要设置密码。</p><h3 id="_4、hadoop是否遵循unix模式" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#4hadoop%E6%98%AF%E5%90%A6%E9%81%B5%E5%BE%AAunix%E6%A8%A1%E5%BC%8F" target="_blank" rel="noreferrer">4、Hadoop是否遵循UNIX模式？</a> <a class="header-anchor" href="#_4、hadoop是否遵循unix模式" aria-label="Permalink to &quot;[4、Hadoop是否遵循UNIX模式？](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题，2021年面试题及答案汇总.md#4hadoop是否遵循unix模式)&quot;">​</a></h3><p>是的，在UNIX用例下，Hadoop还拥有“conf”目录。</p><h3 id="_5、请描述一下开发过程中如何对上面的程序进行性能分析-对性能分析进行优化的过程。" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#5%E8%AF%B7%E6%8F%8F%E8%BF%B0%E4%B8%80%E4%B8%8B%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%A6%82%E4%BD%95%E5%AF%B9%E4%B8%8A%E9%9D%A2%E7%9A%84%E7%A8%8B%E5%BA%8F%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%AF%B9%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E8%BF%9B%E8%A1%8C%E4%BC%98%E5%8C%96%E7%9A%84%E8%BF%87%E7%A8%8B%E3%80%82" target="_blank" rel="noreferrer">5、请描述一下开发过程中如何对上面的程序进行性能分析，对性能分析进行优化的过程。</a> <a class="header-anchor" href="#_5、请描述一下开发过程中如何对上面的程序进行性能分析-对性能分析进行优化的过程。" aria-label="Permalink to &quot;[5、请描述一下开发过程中如何对上面的程序进行性能分析，对性能分析进行优化的过程。](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题，2021年面试题及答案汇总.md#5请描述一下开发过程中如何对上面的程序进行性能分析对性能分析进行优化的过程。)&quot;">​</a></h3><p>现有 1 亿个整数均匀分布，如果要得到前 1K 个最大的数，求最优的算法。</p><p>参见《海量数据算法面试大全》</p><p>95.mapreduce的大致流程</p><p>主要分为八个步骤</p><p>1/对文件进行切片规划</p><p>2/启动相应数量的maptask进程</p><p>3/调用FileInputFormat中的RecordReader，读一行数据并封装为k1v1</p><p>4/调用自定义的map函数，并将k1v1传给map</p><p>5/收集map的输出，进行分区和排序</p><p>6/reduce task任务启动，并从map端拉取数据</p><p>7/reduce task调用自定义的reduce函数进行处理</p><p>8/调用outputformat的recordwriter将结果数据输出</p><h3 id="_6、请简述mapreduce中的combine和partition的作用" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#6%E8%AF%B7%E7%AE%80%E8%BF%B0mapreduce%E4%B8%AD%E7%9A%84combine%E5%92%8Cpartition%E7%9A%84%E4%BD%9C%E7%94%A8" target="_blank" rel="noreferrer">6、请简述mapreduce中的combine和partition的作用</a> <a class="header-anchor" href="#_6、请简述mapreduce中的combine和partition的作用" aria-label="Permalink to &quot;[6、请简述mapreduce中的combine和partition的作用](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题，2021年面试题及答案汇总.md#6请简述mapreduce中的combine和partition的作用)&quot;">​</a></h3><p>combiner是发生在map的最后一个阶段，其原理也是一个小型的reducer，主要作用是减少输出到reduce的数据量，缓解网络传输瓶颈，提高reducer的执行效率。</p><p>partition的主要作用将map阶段产生的所有kv对分配给不同的reducer task处理，可以将reduce阶段的处理负载进行分摊</p><h3 id="_7、hadoop的shuffle过程" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#7hadoop%E7%9A%84shuffle%E8%BF%87%E7%A8%8B" target="_blank" rel="noreferrer">7、Hadoop的shuffle过程</a> <a class="header-anchor" href="#_7、hadoop的shuffle过程" aria-label="Permalink to &quot;[7、Hadoop的shuffle过程](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题，2021年面试题及答案汇总.md#7hadoop的shuffle过程)&quot;">​</a></h3><p><strong>Map端的shuffle</strong></p><p>Map端会处理输入数据并产生中间结果，这个中间结果会写到本地磁盘，而不是HDFS。每个Map的输出会先写到内存缓冲区中，当写入的数据达到设定的阈值时，系统将会启动一个线程将缓冲区的数据写到磁盘，这个过程叫做spill。</p><p>在spill写入之前，会先进行二次排序，首先根据数据所属的partition进行排序，然后每个partition中的数据再按key来排序。partition的目是将记录划分到不同的Reducer上去，以期望能够达到负载均衡，以后的Reducer就会根据partition来读取自己对应的数据。接着运行combiner(如果设置了的话)，combiner的本质也是一个Reducer，其目的是对将要写入到磁盘上的文件先进行一次处理，这样，写入到磁盘的数据量就会减少。最后将数据写到本地磁盘产生spill文件(spill文件保存在{mapred.local.dir}指定的目录中，Map任务结束后就会被删除)。</p><p>最后，每个Map任务可能产生多个spill文件，在每个Map任务完成前，会通过多路归并算法将这些spill文件归并成一个文件。至此，Map的shuffle过程就结束了。</p><p><strong>Reduce端的shuffle</strong></p><p>Reduce端的shuffle主要包括三个阶段，copy、sort(merge)和reduce。</p><p>首先要将Map端产生的输出文件拷贝到Reduce端，但每个Reducer如何知道自己应该处理哪些数据呢？</p><p>因为Map端进行partition的时候，实际上就相当于指定了每个Reducer要处理的数据(partition就对应了Reducer)，所以Reducer在拷贝数据的时候只需拷贝与自己对应的partition中的数据即可。</p><p>每个Reducer会处理一个或者多个partition，但需要先将自己对应的partition中的数据从每个Map的输出结果中拷贝过来。</p><p>接下来就是sort阶段，也成为merge阶段，因为这个阶段的主要工作是执行了归并排序。</p><p>从Map端拷贝到Reduce端的数据都是有序的，所以很适合归并排序。</p><p>最终在Reduce端生成一个较大的文件作为Reduce的输入。</p><p>最后就是Reduce过程了，在这个过程中产生了最终的输出结果，并将其写到HDFS上。</p><h3 id="_8、什么是kafka" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#8%E4%BB%80%E4%B9%88%E6%98%AFkafka" target="_blank" rel="noreferrer">8、什么是Kafka？</a> <a class="header-anchor" href="#_8、什么是kafka" aria-label="Permalink to &quot;[8、什么是Kafka？](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题，2021年面试题及答案汇总.md#8什么是kafka)&quot;">​</a></h3><p>开源消息系统，由scala写成</p><p>Kafka是一个分布式消息队列：生产者、消费者的功能，他提供类似于JMS的特性，但是设计上完全不同，此外它并不是JMS规范的实现</p><p>Kafka对消息保存 根据Topic进行归类，Producer生产者为发送消息 ，接收消息为Consumer 消费者，Kafka集群有多个Kafka实例组成，每个实例为broker</p><p>Kafka所有组件都依赖于Zookeeper集群保存一些元数据信息，来保证系统可用性</p><h3 id="_9、hbase的rowkey怎么创建比较好-列簇怎么创建比较好" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#9hbase%E7%9A%84rowkey%E6%80%8E%E4%B9%88%E5%88%9B%E5%BB%BA%E6%AF%94%E8%BE%83%E5%A5%BD%E5%88%97%E7%B0%87%E6%80%8E%E4%B9%88%E5%88%9B%E5%BB%BA%E6%AF%94%E8%BE%83%E5%A5%BD" target="_blank" rel="noreferrer">9、Hbase的rowKey怎么创建比较好？列簇怎么创建比较好？</a> <a class="header-anchor" href="#_9、hbase的rowkey怎么创建比较好-列簇怎么创建比较好" aria-label="Permalink to &quot;[9、Hbase的rowKey怎么创建比较好？列簇怎么创建比较好？](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题，2021年面试题及答案汇总.md#9hbase的rowkey怎么创建比较好列簇怎么创建比较好)&quot;">​</a></h3><p>rowKey最好要创建有规则的rowKey，即最好是有序的。</p><p>经常需要批量读取的数据应该让他们的rowkey连续；</p><p>将经常需要作为条件查询的关键词组织到rowkey中；</p><p>列族的创建：</p><p>按照业务特点，把数据归类，不同类别的放在不同列族</p><h3 id="_10、hadoop-metrics-properties文件的作用是" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%8C2021%E5%B9%B4%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#10hadoop-metricsproperties%E6%96%87%E4%BB%B6%E7%9A%84%E4%BD%9C%E7%94%A8%E6%98%AF" target="_blank" rel="noreferrer">10、hadoop-metrics.properties文件的作用是？</a> <a class="header-anchor" href="#_10、hadoop-metrics-properties文件的作用是" aria-label="Permalink to &quot;[10、hadoop-metrics.properties文件的作用是？](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题，2021年面试题及答案汇总.md#10hadoop-metricsproperties文件的作用是)&quot;">​</a></h3><p>hadoop-metrics.properties被用做“Reporting”，控制Hadoop报告，初始状态是“not to report”。</p><h3 id="_11、描述hbase-zookeeper搭建过程" tabindex="-1">11、描述Hbase，ZooKeeper搭建过程 <a class="header-anchor" href="#_11、描述hbase-zookeeper搭建过程" aria-label="Permalink to &quot;11、描述Hbase，ZooKeeper搭建过程&quot;">​</a></h3><h3 id="_12、sqoop在导入数据到mysql中-如何不重复导入数据-如果存在数据问题-sqoop如何处理" tabindex="-1">12、sqoop在导入数据到MySQL中，如何不重复导入数据，如果存在数据问题，sqoop如何处理？ <a class="header-anchor" href="#_12、sqoop在导入数据到mysql中-如何不重复导入数据-如果存在数据问题-sqoop如何处理" aria-label="Permalink to &quot;12、sqoop在导入数据到MySQL中，如何不重复导入数据，如果存在数据问题，sqoop如何处理？&quot;">​</a></h3><h3 id="_13、hadoop-env-sh文件当下的位置" tabindex="-1">13、Hadoop-env.sh文件当下的位置？ <a class="header-anchor" href="#_13、hadoop-env-sh文件当下的位置" aria-label="Permalink to &quot;13、Hadoop-env.sh文件当下的位置？&quot;">​</a></h3><h3 id="_14、masters由什么组成" tabindex="-1">14、Masters由什么组成？ <a class="header-anchor" href="#_14、masters由什么组成" aria-label="Permalink to &quot;14、Masters由什么组成？&quot;">​</a></h3><h3 id="_15、hadoop的核心配置是什么" tabindex="-1">15、Hadoop的核心配置是什么？ <a class="header-anchor" href="#_15、hadoop的核心配置是什么" aria-label="Permalink to &quot;15、Hadoop的核心配置是什么？&quot;">​</a></h3><h3 id="_16、我们使用ubuntu及cloudera-那么我们该去哪里下载hadoop-或者是默认就与ubuntu一起安装" tabindex="-1">16、我们使用Ubuntu及Cloudera，那么我们该去哪里下载Hadoop，或者是默认就与Ubuntu一起安装？ <a class="header-anchor" href="#_16、我们使用ubuntu及cloudera-那么我们该去哪里下载hadoop-或者是默认就与ubuntu一起安装" aria-label="Permalink to &quot;16、我们使用Ubuntu及Cloudera，那么我们该去哪里下载Hadoop，或者是默认就与Ubuntu一起安装？&quot;">​</a></h3><h3 id="_17、腾讯面试题-给40亿个不重复的unsigned-int的整数-没排过序的-然后再给一个数-如何快速判断这个数是否在那40亿个数当中" tabindex="-1">17、腾讯面试题：给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？ <a class="header-anchor" href="#_17、腾讯面试题-给40亿个不重复的unsigned-int的整数-没排过序的-然后再给一个数-如何快速判断这个数是否在那40亿个数当中" aria-label="Permalink to &quot;17、腾讯面试题：给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？&quot;">​</a></h3><h3 id="_18、ssh工作的端口号是" tabindex="-1">18、SSH工作的端口号是？ <a class="header-anchor" href="#_18、ssh工作的端口号是" aria-label="Permalink to &quot;18、SSH工作的端口号是？&quot;">​</a></h3><h3 id="_19、hadoop集群可以运行的3个模式" tabindex="-1">19、Hadoop集群可以运行的3个模式？ <a class="header-anchor" href="#_19、hadoop集群可以运行的3个模式" aria-label="Permalink to &quot;19、Hadoop集群可以运行的3个模式？&quot;">​</a></h3><h3 id="_20、列族怎么创建比较好-2" tabindex="-1">20、列族怎么创建比较好 &lt;=2 <a class="header-anchor" href="#_20、列族怎么创建比较好-2" aria-label="Permalink to &quot;20、列族怎么创建比较好 &lt;=2&quot;">​</a></h3><h3 id="_21、hadoop框架怎么来优化" tabindex="-1">21、hadoop框架怎么来优化 <a class="header-anchor" href="#_21、hadoop框架怎么来优化" aria-label="Permalink to &quot;21、hadoop框架怎么来优化&quot;">​</a></h3><h3 id="_22、介绍一下join操作优化经验" tabindex="-1">22、介绍一下join操作优化经验？ <a class="header-anchor" href="#_22、介绍一下join操作优化经验" aria-label="Permalink to &quot;22、介绍一下join操作优化经验？&quot;">​</a></h3><h3 id="_23、简单说一下hadoop和spark的shuffle过程" tabindex="-1">23、简单说一下hadoop和spark的shuffle过程 <a class="header-anchor" href="#_23、简单说一下hadoop和spark的shuffle过程" aria-label="Permalink to &quot;23、简单说一下hadoop和spark的shuffle过程&quot;">​</a></h3><h3 id="_24、描述一下hadoop中-有哪些地方使用到了缓存机制-作用分别是什么" tabindex="-1">24、描述一下hadoop中，有哪些地方使用到了缓存机制，作用分别是什么？ <a class="header-anchor" href="#_24、描述一下hadoop中-有哪些地方使用到了缓存机制-作用分别是什么" aria-label="Permalink to &quot;24、描述一下hadoop中，有哪些地方使用到了缓存机制，作用分别是什么？&quot;">​</a></h3><h3 id="_25、说一下rdd-的lineage血统" tabindex="-1">25、说一下RDD 的Lineage血统 <a class="header-anchor" href="#_25、说一下rdd-的lineage血统" aria-label="Permalink to &quot;25、说一下RDD 的Lineage血统&quot;">​</a></h3><h3 id="_26、hbase内部机制是什么" tabindex="-1">26、hbase内部机制是什么 <a class="header-anchor" href="#_26、hbase内部机制是什么" aria-label="Permalink to &quot;26、hbase内部机制是什么&quot;">​</a></h3><h3 id="_27、当job-tracker宕掉时-namenode会发生什么" tabindex="-1">27、当Job Tracker宕掉时，Namenode会发生什么？ <a class="header-anchor" href="#_27、当job-tracker宕掉时-namenode会发生什么" aria-label="Permalink to &quot;27、当Job Tracker宕掉时，Namenode会发生什么？&quot;">​</a></h3><h3 id="_28、如何检查namenode是否正常运行" tabindex="-1">28、如何检查Namenode是否正常运行？ <a class="header-anchor" href="#_28、如何检查namenode是否正常运行" aria-label="Permalink to &quot;28、如何检查Namenode是否正常运行？&quot;">​</a></h3><h3 id="_29、flume的工作及时是什么" tabindex="-1">29、Flume的工作及时是什么？ <a class="header-anchor" href="#_29、flume的工作及时是什么" aria-label="Permalink to &quot;29、Flume的工作及时是什么？&quot;">​</a></h3><h3 id="_30、hadoop需求什么样的网络" tabindex="-1">30、Hadoop需求什么样的网络？ <a class="header-anchor" href="#_30、hadoop需求什么样的网络" aria-label="Permalink to &quot;30、Hadoop需求什么样的网络？&quot;">​</a></h3><h3 id="_31、kafka的消费" tabindex="-1">31、Kafka的消费 <a class="header-anchor" href="#_31、kafka的消费" aria-label="Permalink to &quot;31、Kafka的消费&quot;">​</a></h3><h3 id="_32、hdfs运行原理" tabindex="-1">32、hdfs运行原理 <a class="header-anchor" href="#_32、hdfs运行原理" aria-label="Permalink to &quot;32、hdfs运行原理&quot;">​</a></h3>',77),s=[E];function d(h,p,i,n,l,u){return e(),o("div",null,s)}const B=a(t,[["render",d]]);export{c as __pageData,B as default};
