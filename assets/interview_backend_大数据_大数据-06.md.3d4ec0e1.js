import{_ as e,o as a,c as o,V as E}from"./chunks/framework.c6d8cbec.js";const c=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"interview/backend/大数据/大数据-06.md","filePath":"interview/backend/大数据/大数据-06.md"}'),r={name:"interview/backend/大数据/大数据-06.md"},t=E('<h3 id="_1、谈谈zookeeper理解" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#1%E8%B0%88%E8%B0%88zookeeper%E7%90%86%E8%A7%A3" target="_blank" rel="noreferrer">1、谈谈Zookeeper理解</a> <a class="header-anchor" href="#_1、谈谈zookeeper理解" aria-label="Permalink to &quot;[1、谈谈Zookeeper理解](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题2021年，常见面试题及答案汇总.md#1谈谈zookeeper理解)&quot;">​</a></h3><p>Zookeeper 作为一个分布式的服务框架，主要用来解决分布式集群中应用系统的一致性问题( 解决单点故障问题 )。</p><p>Zookeeper 并不是用来专门存储数据的，它的作用主要是用来维护和监控你存储的数据的状态变化，通过监控这些数据状态的变化，从而可以达到基于数据的集群管理</p><p>总结: Zookeeper=文件系统+通知机制</p><p>spark</p><h3 id="_2、请列举出曾经修改过的-etc-下面的文件-并说明修改要解决什么问题" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#2%E8%AF%B7%E5%88%97%E4%B8%BE%E5%87%BA%E6%9B%BE%E7%BB%8F%E4%BF%AE%E6%94%B9%E8%BF%87%E7%9A%84/etc/%E4%B8%8B%E9%9D%A2%E7%9A%84%E6%96%87%E4%BB%B6%E5%B9%B6%E8%AF%B4%E6%98%8E%E4%BF%AE%E6%94%B9%E8%A6%81%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98" target="_blank" rel="noreferrer">2、请列举出曾经修改过的/etc/下面的文件，并说明修改要解决什么问题？</a> <a class="header-anchor" href="#_2、请列举出曾经修改过的-etc-下面的文件-并说明修改要解决什么问题" aria-label="Permalink to &quot;[2、请列举出曾经修改过的/etc/下面的文件，并说明修改要解决什么问题？](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题2021年，常见面试题及答案汇总.md#2请列举出曾经修改过的/etc/下面的文件并说明修改要解决什么问题)&quot;">​</a></h3><p>/etc/profile这个文件，主要是用来配置环境变量。让hadoop命令可以在任意目录下面执行。</p><p>/ect/sudoers</p><p>/etc/hosts</p><p>/etc/sysconfig/network</p><p>/etc/inittab</p><h3 id="_3、宕机分为hmaster宕机和hregisoner宕机-如果是hregisoner宕机-hmaster会将其所管理的region重新分布到其他活动的regionserver上-由于数据和日志都持久在hdfs中-该操作不会导致数据丢失。所以数据的一致性和安全性是有保障的。" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#3%E5%AE%95%E6%9C%BA%E5%88%86%E4%B8%BAhmaster%E5%AE%95%E6%9C%BA%E5%92%8Chregisoner%E5%AE%95%E6%9C%BA%E5%A6%82%E6%9E%9C%E6%98%AFhregisoner%E5%AE%95%E6%9C%BAhmaster%E4%BC%9A%E5%B0%86%E5%85%B6%E6%89%80%E7%AE%A1%E7%90%86%E7%9A%84region%E9%87%8D%E6%96%B0%E5%88%86%E5%B8%83%E5%88%B0%E5%85%B6%E4%BB%96%E6%B4%BB%E5%8A%A8%E7%9A%84regionserver%E4%B8%8A%E7%94%B1%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%92%8C%E6%97%A5%E5%BF%97%E9%83%BD%E6%8C%81%E4%B9%85%E5%9C%A8hdfs%E4%B8%AD%E8%AF%A5%E6%93%8D%E4%BD%9C%E4%B8%8D%E4%BC%9A%E5%AF%BC%E8%87%B4%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E3%80%82%E6%89%80%E4%BB%A5%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%E5%92%8C%E5%AE%89%E5%85%A8%E6%80%A7%E6%98%AF%E6%9C%89%E4%BF%9D%E9%9A%9C%E7%9A%84%E3%80%82" target="_blank" rel="noreferrer">3、宕机分为HMaster宕机和HRegisoner宕机，如果是HRegisoner宕机，HMaster会将其所管理的region重新分布到其他活动的RegionServer上，由于数据和日志都持久在HDFS中，该操作不会导致数据丢失。所以数据的一致性和安全性是有保障的。</a> <a class="header-anchor" href="#_3、宕机分为hmaster宕机和hregisoner宕机-如果是hregisoner宕机-hmaster会将其所管理的region重新分布到其他活动的regionserver上-由于数据和日志都持久在hdfs中-该操作不会导致数据丢失。所以数据的一致性和安全性是有保障的。" aria-label="Permalink to &quot;[3、宕机分为HMaster宕机和HRegisoner宕机，如果是HRegisoner宕机，HMaster会将其所管理的region重新分布到其他活动的RegionServer上，由于数据和日志都持久在HDFS中，该操作不会导致数据丢失。所以数据的一致性和安全性是有保障的。](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题2021年，常见面试题及答案汇总.md#3宕机分为hmaster宕机和hregisoner宕机如果是hregisoner宕机hmaster会将其所管理的region重新分布到其他活动的regionserver上由于数据和日志都持久在hdfs中该操作不会导致数据丢失。所以数据的一致性和安全性是有保障的。)&quot;">​</a></h3><p>如果是HMaster宕机，HMaster没有单点问题，HBase中可以启动多个HMaster，通过Zookeeper的Master Election机制保证总有一个Master运行。即ZooKeeper会保证总会有一个HMaster在对外提供服务。</p><h3 id="_4、offset是每天消息的偏移量" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#4offset%E6%98%AF%E6%AF%8F%E5%A4%A9%E6%B6%88%E6%81%AF%E7%9A%84%E5%81%8F%E7%A7%BB%E9%87%8F" target="_blank" rel="noreferrer">4、offset是每天消息的偏移量</a> <a class="header-anchor" href="#_4、offset是每天消息的偏移量" aria-label="Permalink to &quot;[4、offset是每天消息的偏移量](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题2021年，常见面试题及答案汇总.md#4offset是每天消息的偏移量)&quot;">​</a></h3><p>每个日志文件都有一个offset来唯一标记一条信息，由8个自己数字表示，表示此消息在分区中所处的起始位置</p><p>每个分区再物理存储层面，由多个logfile组成（segment）</p><p>最小的offset表示segment中起始消息的offset</p><h3 id="_5、hbase中表的特点" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#5hbase%E4%B8%AD%E8%A1%A8%E7%9A%84%E7%89%B9%E7%82%B9" target="_blank" rel="noreferrer">5、hbase中表的特点</a> <a class="header-anchor" href="#_5、hbase中表的特点" aria-label="Permalink to &quot;[5、hbase中表的特点](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题2021年，常见面试题及答案汇总.md#5hbase中表的特点)&quot;">​</a></h3><p>大：上亿行，上百万列</p><p>无模式：每行都有一个可排序的主键和任意多的列，列可以根据需要动态增加，同一张表中不同的行可以有截然不同的列</p><p>面向列的存储和权限控制，列族独立索引</p><p>对于为null的列，并不占用存储空间，因此表可以设置的非常稀疏</p><p>数据多版本：可以有多个版本，系统自动分配，时间戳为版本号</p><p>数据类型单一：只有字节数组 byte[]</p><p>129.hbase 表逻辑结构</p><p>表有 行 和 列组成，列划分为若干个列族cloumn</p><p>表明 test</p><p>rowkey 列族1：base_info 列族2：xxx_info</p><p>0001 name:zhangsan age:20 address:bj</p><p>0002 name:lishi age:50 sex:male address:shanghai hoppies:sing</p><p>rowkey:hbase的行索引，按照rowkey字典顺序排序</p><p>cell可以锁定一个值：Rowkey+列族+列族下的列的名字+值+时间戳</p><h3 id="_6、请写出以下的shell命令" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#6%E8%AF%B7%E5%86%99%E5%87%BA%E4%BB%A5%E4%B8%8B%E7%9A%84shell%E5%91%BD%E4%BB%A4" target="_blank" rel="noreferrer">6、请写出以下的shell命令</a> <a class="header-anchor" href="#_6、请写出以下的shell命令" aria-label="Permalink to &quot;[6、请写出以下的shell命令](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题2021年，常见面试题及答案汇总.md#6请写出以下的shell命令)&quot;">​</a></h3><p><strong>1、</strong> 杀死一个job</p><p><strong>2、</strong> 删除hdfs上的 /tmp/aaa目录</p><p><strong>3、</strong> 加入一个新的存储节点和删除一个节点需要执行的命令</p><p><strong>4、</strong> hadoop job –list 得到job的id，然后执 行 hadoop job -kill jobId就可以杀死一个指定jobId的job工作了。</p><p><strong>5、</strong> hadoopfs -rmr /tmp/aaa</p><p><strong>6、</strong> 增加一个新的节点在新的几点上执行</p><p>Hadoop daemon.sh start datanode</p><p>Hadooop daemon.sh start tasktracker/nodemanager</p><p>下线时，要在conf目录下的excludes文件中列出要下线的datanode机器主机名</p><p>然后在主节点中执行 hadoop dfsadmin -refreshnodes à下线一个datanode</p><p>删除一个节点的时候，只需要在主节点执行</p><p>hadoop mradmin -refreshnodes —下线一个tasktracker/nodemanager</p><h3 id="_7、简答说一下hadoop的map-reduce编程模型" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#7%E7%AE%80%E7%AD%94%E8%AF%B4%E4%B8%80%E4%B8%8Bhadoop%E7%9A%84map-reduce%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B" target="_blank" rel="noreferrer">7、简答说一下hadoop的map-reduce编程模型</a> <a class="header-anchor" href="#_7、简答说一下hadoop的map-reduce编程模型" aria-label="Permalink to &quot;[7、简答说一下hadoop的map-reduce编程模型](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题2021年，常见面试题及答案汇总.md#7简答说一下hadoop的map-reduce编程模型)&quot;">​</a></h3><p>首先map task会从本地文件系统读取数据，转换成key-value形式的键值对集合</p><p>使用的是hadoop内置的数据类型，比如longwritable、text等</p><p>将键值对集合输入mapper进行业务处理过程，将其转换成需要的key-value在输出</p><p>之后会进行一个partition分区操作，默认使用的是hashpartitioner，可以通过重写hashpartitioner的getpartition方法来自定义分区规则</p><p>之后会对key进行进行sort排序，grouping分组操作将相同key的value合并分组输出，在这里可以使用自定义的数据类型，重写WritableComparator的Comparator方法来自定义排序规则，重写RawComparator的compara方法来自定义分组规则</p><p>之后进行一个combiner归约操作，其实就是一个本地段的reduce预处理，以减小后面shufle和reducer的工作量</p><p>reduce task会通过网络将各个数据收集进行reduce处理，最后将数据保存或者显示，结束整个job</p><h3 id="_8、mr程序运行的时候会有什么比较常见的问题" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#8mr%E7%A8%8B%E5%BA%8F%E8%BF%90%E8%A1%8C%E7%9A%84%E6%97%B6%E5%80%99%E4%BC%9A%E6%9C%89%E4%BB%80%E4%B9%88%E6%AF%94%E8%BE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E9%97%AE%E9%A2%98" target="_blank" rel="noreferrer">8、MR程序运行的时候会有什么比较常见的问题？</a> <a class="header-anchor" href="#_8、mr程序运行的时候会有什么比较常见的问题" aria-label="Permalink to &quot;[8、MR程序运行的时候会有什么比较常见的问题？](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题2021年，常见面试题及答案汇总.md#8mr程序运行的时候会有什么比较常见的问题)&quot;">​</a></h3><p>比如说作业中大部分都完成了，但是总有几个reduce一直在运行。</p><p>这是因为这几个reduce中的处理的数据要远远大于其他的reduce，可能是对键值对任务划分的不均匀造成的数据倾斜。</p><p>解决的方法可以在分区的时候重新定义分区规则对于value数据很多的key可以进行拆分、均匀打散等处理，或者是在map端的combiner中进行数据预处理的操作。</p><h3 id="_9、hive能像关系型数据库那样建多个库吗" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#9hive%E8%83%BD%E5%83%8F%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E9%82%A3%E6%A0%B7%E5%BB%BA%E5%A4%9A%E4%B8%AA%E5%BA%93%E5%90%97" target="_blank" rel="noreferrer">9、hive能像关系型数据库那样建多个库吗？</a> <a class="header-anchor" href="#_9、hive能像关系型数据库那样建多个库吗" aria-label="Permalink to &quot;[9、hive能像关系型数据库那样建多个库吗？](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题2021年，常见面试题及答案汇总.md#9hive能像关系型数据库那样建多个库吗)&quot;">​</a></h3><p>当然能了。</p><ol start="106"><li></li></ol><h3 id="_10、请列出你所知道的hadoop调度器-并简要说明其工作方法" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%982021%E5%B9%B4%EF%BC%8C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#10%E8%AF%B7%E5%88%97%E5%87%BA%E4%BD%A0%E6%89%80%E7%9F%A5%E9%81%93%E7%9A%84hadoop%E8%B0%83%E5%BA%A6%E5%99%A8%E5%B9%B6%E7%AE%80%E8%A6%81%E8%AF%B4%E6%98%8E%E5%85%B6%E5%B7%A5%E4%BD%9C%E6%96%B9%E6%B3%95" target="_blank" rel="noreferrer">10、请列出你所知道的hadoop调度器，并简要说明其工作方法</a> <a class="header-anchor" href="#_10、请列出你所知道的hadoop调度器-并简要说明其工作方法" aria-label="Permalink to &quot;[10、请列出你所知道的hadoop调度器，并简要说明其工作方法](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新面试题2021年，常见面试题及答案汇总.md#10请列出你所知道的hadoop调度器并简要说明其工作方法)&quot;">​</a></h3><p>Fifo schedular :默认，先进先出的原则</p><p>Capacity schedular :计算能力调度器，选择占用最小、优先级高的先执行，依此类推。</p><p>Fair schedular:公平调度，所有的 job 具有相同的资源。</p><h3 id="_11、请描述如何解决hbase中region太小和region太大带来的结果。" tabindex="-1">11、请描述如何解决Hbase中region太小和region太大带来的结果。 <a class="header-anchor" href="#_11、请描述如何解决hbase中region太小和region太大带来的结果。" aria-label="Permalink to &quot;11、请描述如何解决Hbase中region太小和region太大带来的结果。&quot;">​</a></h3><h3 id="_12、hive如何优化" tabindex="-1">12、hive如何优化 <a class="header-anchor" href="#_12、hive如何优化" aria-label="Permalink to &quot;12、hive如何优化&quot;">​</a></h3><h3 id="_13、怎么设置rdd-cache" tabindex="-1">13、怎么设置RDD cache <a class="header-anchor" href="#_13、怎么设置rdd-cache" aria-label="Permalink to &quot;13、怎么设置RDD cache&quot;">​</a></h3><h3 id="_14、你们数据库如何导入hive的出现什么错误" tabindex="-1">14、你们数据库如何导入hive的出现什么错误 <a class="header-anchor" href="#_14、你们数据库如何导入hive的出现什么错误" aria-label="Permalink to &quot;14、你们数据库如何导入hive的出现什么错误&quot;">​</a></h3><h3 id="_15、hadoop-的-namenode-宕机怎么解决" tabindex="-1">15、hadoop 的 namenode 宕机怎么解决 <a class="header-anchor" href="#_15、hadoop-的-namenode-宕机怎么解决" aria-label="Permalink to &quot;15、hadoop 的 namenode 宕机怎么解决&quot;">​</a></h3><h3 id="_16、shuffle阶段你怎么理解" tabindex="-1">16、shuffle阶段你怎么理解 <a class="header-anchor" href="#_16、shuffle阶段你怎么理解" aria-label="Permalink to &quot;16、shuffle阶段你怎么理解&quot;">​</a></h3><h3 id="_17、数据导入hive的方式" tabindex="-1">17、数据导入hive的方式 <a class="header-anchor" href="#_17、数据导入hive的方式" aria-label="Permalink to &quot;17、数据导入hive的方式&quot;">​</a></h3><h3 id="_18、如何从su转到cloudera" tabindex="-1">18、如何从SU转到Cloudera？ <a class="header-anchor" href="#_18、如何从su转到cloudera" aria-label="Permalink to &quot;18、如何从SU转到Cloudera？&quot;">​</a></h3><h3 id="_19、数据库-olap-oltp的介绍和比较" tabindex="-1">19、数据库 OLAP OLTP的介绍和比较 <a class="header-anchor" href="#_19、数据库-olap-oltp的介绍和比较" aria-label="Permalink to &quot;19、数据库 OLAP OLTP的介绍和比较&quot;">​</a></h3><h3 id="_20、hive与传统db的区别" tabindex="-1">20、hive与传统DB的区别 <a class="header-anchor" href="#_20、hive与传统db的区别" aria-label="Permalink to &quot;20、hive与传统DB的区别&quot;">​</a></h3><h3 id="_21、搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来-每个查询串的长度为1-255字节。" tabindex="-1">21、搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。 <a class="header-anchor" href="#_21、搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来-每个查询串的长度为1-255字节。" aria-label="Permalink to &quot;21、搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。&quot;">​</a></h3><h3 id="_22、为什么ssh本地主机需要密码" tabindex="-1">22、为什么SSH本地主机需要密码？ <a class="header-anchor" href="#_22、为什么ssh本地主机需要密码" aria-label="Permalink to &quot;22、为什么SSH本地主机需要密码？&quot;">​</a></h3><h3 id="_23、全分布式环境下为什么需求password-less-ssh" tabindex="-1">23、全分布式环境下为什么需求password-less SSH？ <a class="header-anchor" href="#_23、全分布式环境下为什么需求password-less-ssh" aria-label="Permalink to &quot;23、全分布式环境下为什么需求password-less SSH？&quot;">​</a></h3><h3 id="_24、为什么会出现hadoop" tabindex="-1">24、为什么会出现hadoop <a class="header-anchor" href="#_24、为什么会出现hadoop" aria-label="Permalink to &quot;24、为什么会出现hadoop&quot;">​</a></h3><h3 id="_25、运行hadoop集群需要哪些守护进程" tabindex="-1">25、运行hadoop集群需要哪些守护进程？ <a class="header-anchor" href="#_25、运行hadoop集群需要哪些守护进程" aria-label="Permalink to &quot;25、运行hadoop集群需要哪些守护进程？&quot;">​</a></h3><h3 id="_26、hbase简单读写流程" tabindex="-1">26、HBase简单读写流程？ <a class="header-anchor" href="#_26、hbase简单读写流程" aria-label="Permalink to &quot;26、HBase简单读写流程？&quot;">​</a></h3><h3 id="_27、hive是什么" tabindex="-1">27、hive是什么 <a class="header-anchor" href="#_27、hive是什么" aria-label="Permalink to &quot;27、hive是什么&quot;">​</a></h3><h3 id="_28、怎么样才能实现去掉reduce阶段" tabindex="-1">28、怎么样才能实现去掉reduce阶段 <a class="header-anchor" href="#_28、怎么样才能实现去掉reduce阶段" aria-label="Permalink to &quot;28、怎么样才能实现去掉reduce阶段&quot;">​</a></h3><h3 id="_29、使用zk来连接集群" tabindex="-1">29、使用zk来连接集群 <a class="header-anchor" href="#_29、使用zk来连接集群" aria-label="Permalink to &quot;29、使用zk来连接集群&quot;">​</a></h3><h3 id="_30、上千万或上亿数据-有重复-统计其中出现次数最多的前n个数据。" tabindex="-1">30、上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据。 <a class="header-anchor" href="#_30、上千万或上亿数据-有重复-统计其中出现次数最多的前n个数据。" aria-label="Permalink to &quot;30、上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据。&quot;">​</a></h3><h3 id="_31、hive中存放的是什么" tabindex="-1">31、hive中存放的是什么？ <a class="header-anchor" href="#_31、hive中存放的是什么" aria-label="Permalink to &quot;31、hive中存放的是什么？&quot;">​</a></h3><h3 id="_32、举一个例子说明mapreduce是怎么运行的。" tabindex="-1">32、举一个例子说明mapreduce是怎么运行的。 <a class="header-anchor" href="#_32、举一个例子说明mapreduce是怎么运行的。" aria-label="Permalink to &quot;32、举一个例子说明mapreduce是怎么运行的。&quot;">​</a></h3>',86),s=[t];function h(A,i,B,d,n,l){return a(),o("div",null,s)}const u=e(r,[["render",h]]);export{c as __pageData,u as default};
