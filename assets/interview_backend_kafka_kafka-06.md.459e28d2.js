import{_ as a,o as e,c as r,V as o}from"./chunks/framework.c6d8cbec.js";const d=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"interview/backend/kafka/kafka-06.md","filePath":"interview/backend/kafka/kafka-06.md"}'),t={name:"interview/backend/kafka/kafka-06.md"},k=o('<h3 id="_1、kafka-producer如何优化写入速度" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E9%99%84%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#1kafka-producer%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%E5%86%99%E5%85%A5%E9%80%9F%E5%BA%A6" target="_blank" rel="noreferrer">1、Kafka Producer如何优化写入速度?</a> <a class="header-anchor" href="#_1、kafka-producer如何优化写入速度" aria-label="Permalink to &quot;[1、Kafka Producer如何优化写入速度?](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题及答案附答案汇总.md#1kafka-producer如何优化写入速度)&quot;">​</a></h3><ol><li>增加线程</li><li>提高 batch.size</li><li>增加更多 producer 实例</li><li>增加 partition 数</li><li>设置 acks=-1 时，如果延迟增大：可以增大 num.replica.fetchers（follower 同步数据的线程数）来调解；</li><li>跨数据中心的传输：增加 socket 缓冲区设置以及 OS tcp 缓冲区设置。</li></ol><h3 id="_2、生产者中-什么情况下会发生-queuefullexception" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E9%99%84%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#2%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%AD%E4%BB%80%E4%B9%88%E6%83%85%E5%86%B5%E4%B8%8B%E4%BC%9A%E5%8F%91%E7%94%9F-queuefullexception" target="_blank" rel="noreferrer">2、生产者中，什么情况下会发生 QueueFullException？</a> <a class="header-anchor" href="#_2、生产者中-什么情况下会发生-queuefullexception" aria-label="Permalink to &quot;[2、生产者中，什么情况下会发生 QueueFullException？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题及答案附答案汇总.md#2生产者中什么情况下会发生-queuefullexception)&quot;">​</a></h3><p>每当Kafka生产者试图以代理的身份在当时无法处理的速度发送消息时，通常都会发生QueueFullException。但是，为了协作处理增加的负载，用户需要添加足够的代理，因为生产者不会阻止。</p><h3 id="_3、数据传输的事务定义有哪三种" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E9%99%84%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#3%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%AE%9A%E4%B9%89%E6%9C%89%E5%93%AA%E4%B8%89%E7%A7%8D" target="_blank" rel="noreferrer">3、数据传输的事务定义有哪三种？</a> <a class="header-anchor" href="#_3、数据传输的事务定义有哪三种" aria-label="Permalink to &quot;[3、数据传输的事务定义有哪三种？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题及答案附答案汇总.md#3数据传输的事务定义有哪三种)&quot;">​</a></h3><p><strong>和MQTT的事务定义一样都是3种</strong></p><p><strong>1、</strong> 最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输</p><p><strong>2、</strong> 最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.</p><p><strong>3、</strong> 精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被一次而且仅仅被传输一次，这是大家所期望的</p><h3 id="_4、kafka-unclean-配置代表什么-会对-spark-streaming-消费有什么影响" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E9%99%84%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#4kafka-unclean-%E9%85%8D%E7%BD%AE%E4%BB%A3%E8%A1%A8%E4%BB%80%E4%B9%88%E4%BC%9A%E5%AF%B9-spark-streaming-%E6%B6%88%E8%B4%B9%E6%9C%89%E4%BB%80%E4%B9%88%E5%BD%B1%E5%93%8D" target="_blank" rel="noreferrer">4、Kafka Unclean 配置代表什么？会对 spark streaming 消费有什么影响？</a> <a class="header-anchor" href="#_4、kafka-unclean-配置代表什么-会对-spark-streaming-消费有什么影响" aria-label="Permalink to &quot;[4、Kafka Unclean 配置代表什么？会对 spark streaming 消费有什么影响？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题及答案附答案汇总.md#4kafka-unclean-配置代表什么会对-spark-streaming-消费有什么影响)&quot;">​</a></h3><p>unclean.leader.election.enable 为 true 的话，意味着非 ISR 集合的 broker 也可以参与选举，这样有可能就会丢数据，spark streaming在消费过程中拿到的 end offset 会突然变小，导致 spark streaming job 挂掉。如果 unclean.leader.election.enable 参数设置为 true，就有可能发生数据丢失和数据不一致的情况，Kafka 的可靠性就会降低；而如果 unclean.leader.election.enable 参数设置为 false，Kafka 的可用性就会降低。</p><h3 id="_5、kafka-中-consumer-group-是什么概念" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E9%99%84%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#5kafka-%E4%B8%AD-consumer-group-%E6%98%AF%E4%BB%80%E4%B9%88%E6%A6%82%E5%BF%B5" target="_blank" rel="noreferrer">5、Kafka 中 Consumer Group 是什么概念？</a> <a class="header-anchor" href="#_5、kafka-中-consumer-group-是什么概念" aria-label="Permalink to &quot;[5、Kafka 中 Consumer Group 是什么概念？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题及答案附答案汇总.md#5kafka-中-consumer-group-是什么概念)&quot;">​</a></h3><p>同样是逻辑上的概念，是Kafka实现单播和广播两种消息模型的手段。同一个topic的数据，会广播给不同的group；同一个group中的worker，只有一个worker能拿到这个数据。换句话说，对于同一个topic，每个group都可以拿到同样的所有数据，但是数据进入group后只能被其中的一个worker消费。group内的worker可以使用多线程或多进程来实现，也可以将进程分散在多台机器上，worker的数量通常不超过partition的数量，且二者最好保持整数倍关系，因为Kafka在设计时假定了一个partition只能被一个worker消费（同一group内）。</p><h3 id="_6、什么是生产者" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E9%99%84%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#6%E4%BB%80%E4%B9%88%E6%98%AF%E7%94%9F%E4%BA%A7%E8%80%85" target="_blank" rel="noreferrer">6、什么是生产者？</a> <a class="header-anchor" href="#_6、什么是生产者" aria-label="Permalink to &quot;[6、什么是生产者？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题及答案附答案汇总.md#6什么是生产者)&quot;">​</a></h3><p>生产者的主要作用是将数据到他们选择的主题上。基本上，它的职责是选择要分配给主题内分区的记录。</p><h3 id="_7、kafka-与传统消息系统之间有三个关键区别" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E9%99%84%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#7kafka-%E4%B8%8E%E4%BC%A0%E7%BB%9F%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F%E4%B9%8B%E9%97%B4%E6%9C%89%E4%B8%89%E4%B8%AA%E5%85%B3%E9%94%AE%E5%8C%BA%E5%88%AB" target="_blank" rel="noreferrer">7、Kafka 与传统消息系统之间有三个关键区别</a> <a class="header-anchor" href="#_7、kafka-与传统消息系统之间有三个关键区别" aria-label="Permalink to &quot;[7、Kafka 与传统消息系统之间有三个关键区别](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题及答案附答案汇总.md#7kafka-与传统消息系统之间有三个关键区别)&quot;">​</a></h3><p><strong>1、</strong> Kafka 持久化日志，这些日志可以被重复读取和无限期保留</p><p><strong>2、</strong> Kafka 是一个分布式系统：它以集群的方式运行，可以灵活伸缩，在内部通过复制数据</p><p><strong>3、</strong> 提升容错能力和高可用性</p><p><strong>4、</strong> Kafka 支持实时的流式处理</p><h3 id="_8、kafka-中是怎么体现消息顺序性的" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E9%99%84%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#8kafka-%E4%B8%AD%E6%98%AF%E6%80%8E%E4%B9%88%E4%BD%93%E7%8E%B0%E6%B6%88%E6%81%AF%E9%A1%BA%E5%BA%8F%E6%80%A7%E7%9A%84" target="_blank" rel="noreferrer">8、Kafka 中是怎么体现消息顺序性的？</a> <a class="header-anchor" href="#_8、kafka-中是怎么体现消息顺序性的" aria-label="Permalink to &quot;[8、Kafka 中是怎么体现消息顺序性的？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题及答案附答案汇总.md#8kafka-中是怎么体现消息顺序性的)&quot;">​</a></h3><p>Kafka 每个 partition 中的消息在写入时都是有序的，消费时，每个 partition 只能被每一个 group 中的一个消费者消费，保证了消费时也是有序的。整个 topic 不保证有序。如果为了保证 topic 整个有序，那么将 partition 调整为1.</p><h3 id="_9、apache-kafka的缺陷" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E9%99%84%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#9apache-kafka%E7%9A%84%E7%BC%BA%E9%99%B7" target="_blank" rel="noreferrer">9、Apache Kafka的缺陷</a> <a class="header-anchor" href="#_9、apache-kafka的缺陷" aria-label="Permalink to &quot;[9、Apache Kafka的缺陷](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题及答案附答案汇总.md#9apache-kafka的缺陷)&quot;">​</a></h3><p>Kafka的局限性是：1.没有完整的监控工具集2.消息调整的</p><h3 id="_10、解释apache-kafka用例" tabindex="-1"><a href="https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka%E6%9C%80%E6%96%B0%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E9%99%84%E7%AD%94%E6%A1%88%E6%B1%87%E6%80%BB.md#10%E8%A7%A3%E9%87%8Aapache-kafka%E7%94%A8%E4%BE%8B" target="_blank" rel="noreferrer">10、解释Apache Kafka用例？</a> <a class="header-anchor" href="#_10、解释apache-kafka用例" aria-label="Permalink to &quot;[10、解释Apache Kafka用例？](https://gitee.com/souyunku/DevBooks/blob/master/docs/Kafka/Kafka最新面试题及答案附答案汇总.md#10解释apache-kafka用例)&quot;">​</a></h3><p>Apache Kafka有很多用例，例如：</p><p><img src="https://gitee.com/souyunkutech/souyunku-home/raw/master/images/souyunku-web/2020/5/1/27/0/9_4.png#alt=9%5C_4.png" alt=""></p><p>Kafka指标可以使用Kafka进行操作监测数据。此外，为了生成操作数据的集中提要，它涉及到从分布式应用程序聚合统计信息。Kafka日志聚合 从组织中的多个服务收集日志。流处理在流处理过程中，Kafka的强耐久性非常有用。Apache Kafka对于新手的面试</p><h3 id="_11、什么是消费者或用户" tabindex="-1">11、什么是消费者或用户？ <a class="header-anchor" href="#_11、什么是消费者或用户" aria-label="Permalink to &quot;11、什么是消费者或用户？&quot;">​</a></h3><h3 id="_12、controller发生网络分区-network-partitioning-时-kafka会怎么样" tabindex="-1">12、Controller发生网络分区（Network Partitioning）时，Kafka会怎么样？ <a class="header-anchor" href="#_12、controller发生网络分区-network-partitioning-时-kafka会怎么样" aria-label="Permalink to &quot;12、Controller发生网络分区（Network Partitioning）时，Kafka会怎么样？&quot;">​</a></h3><h3 id="_13、当ack为-1时-什么情况下-leader-认为一条消息-commit了" tabindex="-1">13、当ack为-1时，什么情况下，Leader 认为一条消息 Commit了？ <a class="header-anchor" href="#_13、当ack为-1时-什么情况下-leader-认为一条消息-commit了" aria-label="Permalink to &quot;13、当ack为-1时，什么情况下，Leader 认为一条消息 Commit了？&quot;">​</a></h3><h3 id="_14、kafka判断一个节点是否还活着有那两个条件" tabindex="-1">14、Kafka判断一个节点是否还活着有那两个条件？ <a class="header-anchor" href="#_14、kafka判断一个节点是否还活着有那两个条件" aria-label="Permalink to &quot;14、Kafka判断一个节点是否还活着有那两个条件？&quot;">​</a></h3><h3 id="_15、偏移的作用是什么" tabindex="-1">15、偏移的作用是什么？ <a class="header-anchor" href="#_15、偏移的作用是什么" aria-label="Permalink to &quot;15、偏移的作用是什么？&quot;">​</a></h3><h3 id="_16、kafka-如何判断节点是否存活" tabindex="-1">16、Kafka 如何判断节点是否存活 <a class="header-anchor" href="#_16、kafka-如何判断节点是否存活" aria-label="Permalink to &quot;16、Kafka 如何判断节点是否存活&quot;">​</a></h3><h3 id="_17、isr在kafka环境中代表什么" tabindex="-1">17、ISR在Kafka环境中代表什么？ <a class="header-anchor" href="#_17、isr在kafka环境中代表什么" aria-label="Permalink to &quot;17、ISR在Kafka环境中代表什么？&quot;">​</a></h3><h3 id="_18、java在apache-kafka中的重要性是什么" tabindex="-1">18、Java在Apache Kafka中的重要性是什么？ <a class="header-anchor" href="#_18、java在apache-kafka中的重要性是什么" aria-label="Permalink to &quot;18、Java在Apache Kafka中的重要性是什么？&quot;">​</a></h3><h3 id="_19、kafka中的-broker-是干什么的" tabindex="-1">19、Kafka中的 Broker 是干什么的？ <a class="header-anchor" href="#_19、kafka中的-broker-是干什么的" aria-label="Permalink to &quot;19、Kafka中的 Broker 是干什么的？&quot;">​</a></h3><h3 id="_20、连接器api的作用是什么" tabindex="-1">20、连接器API的作用是什么？ <a class="header-anchor" href="#_20、连接器api的作用是什么" aria-label="Permalink to &quot;20、连接器API的作用是什么？&quot;">​</a></h3><h3 id="_21、kafka可以接收的消息最大为多少" tabindex="-1">21、Kafka可以接收的消息最大为多少？ <a class="header-anchor" href="#_21、kafka可以接收的消息最大为多少" aria-label="Permalink to &quot;21、Kafka可以接收的消息最大为多少？&quot;">​</a></h3><h3 id="_22、-41-42-43-44-45-47-49apache-kafka对于有经验的人的面试" tabindex="-1">22、：41, 42, 43, 44, 45, 47, 49Apache Kafka对于有经验的人的面试 <a class="header-anchor" href="#_22、-41-42-43-44-45-47-49apache-kafka对于有经验的人的面试" aria-label="Permalink to &quot;22、：41, 42, 43, 44, 45, 47, 49Apache Kafka对于有经验的人的面试&quot;">​</a></h3><h3 id="_23、kafka中有哪几个组件" tabindex="-1">23、Kafka中有哪几个组件? <a class="header-anchor" href="#_23、kafka中有哪几个组件" aria-label="Permalink to &quot;23、Kafka中有哪几个组件?&quot;">​</a></h3><h3 id="_24、kafka-高效文件存储设计特点" tabindex="-1">24、Kafka 高效文件存储设计特点： <a class="header-anchor" href="#_24、kafka-高效文件存储设计特点" aria-label="Permalink to &quot;24、Kafka 高效文件存储设计特点：&quot;">​</a></h3><h3 id="_25、如何设置kafka能接收的最大消息的大小" tabindex="-1">25、如何设置Kafka能接收的最大消息的大小？ <a class="header-anchor" href="#_25、如何设置kafka能接收的最大消息的大小" aria-label="Permalink to &quot;25、如何设置Kafka能接收的最大消息的大小？&quot;">​</a></h3><h3 id="_26、3-不支持通配符主题选择4-速度" tabindex="-1">26、3.不支持通配符主题选择4.速度### <a class="header-anchor" href="#_26、3-不支持通配符主题选择4-速度" aria-label="Permalink to &quot;26、3.不支持通配符主题选择4.速度###&quot;">​</a></h3><h3 id="_27、kafka-判断一个节点是否还活着有那两个条件" tabindex="-1">27、Kafka 判断一个节点是否还活着有那两个条件？ <a class="header-anchor" href="#_27、kafka-判断一个节点是否还活着有那两个条件" aria-label="Permalink to &quot;27、Kafka 判断一个节点是否还活着有那两个条件？&quot;">​</a></h3>',45),E=[k];function n(s,l,i,f,h,c){return e(),r("div",null,E)}const A=a(t,[["render",n]]);export{d as __pageData,A as default};
